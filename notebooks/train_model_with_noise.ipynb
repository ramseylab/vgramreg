{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd88226-4ab6-4d28-88b6-821d3bd6c147",
   "metadata": {},
   "source": [
    "In this experiment, I train the models with noisy data and test the performance on test data.<br>\n",
    "- If the performace of test dataset is comparable with the performance trained on noise free dataset then the data augmentation is helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f6b81df-9557-40eb-9fa0-39690e721106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from src.load_dataset import load_dataset\n",
    "from src.utils import tsen_pca_viz, verify_batch_label_dist, calculate_r2_score, calculate_per_diff, per_error, find_adj_score, combine_all_batches, split_batches_back, perform_combat_normalization\n",
    "from src.load_models import select_model\n",
    "from src.graph_visualization import visualization_testing_dataset\n",
    "from src.config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef56611f-f276-4720-8f2f-62ecdd04f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_create_training_data(train, test):\n",
    "    \n",
    "    X_train = train.drop(columns=['file']).copy()\n",
    "    X_test  = test.drop(columns=['file']).copy()\n",
    "\n",
    "    columns = X_train.columns\n",
    "    \n",
    "    y_train = train['file'].apply(lambda x: int(x.split('_')[-2].replace('cbz','')))\n",
    "    y_test  = test['file'].apply(lambda x: int(x.split('_')[-2].replace('cbz','')))\n",
    "\n",
    "    scaler  = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "\n",
    "    X_train = pd.DataFrame(scaler.transform(X_train), columns=columns)\n",
    "    X_test  = pd.DataFrame(scaler.transform(X_test),  columns=columns)\n",
    "    \n",
    "\n",
    "    X_train.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n",
    "                        'dS_dV_area':'univariate, area(dS/dV)', 'dS_dV_max_peak':'univariate, max(dS/dV)', 'dS_dV_min_peak':'univariate, min(dS/dV)',\\\n",
    "                    'dS_dV_peak_diff':'univariate, max(dS/dV) - min(dS/dV)', \\\n",
    "                    'peak V':'univariate, V_max(S)', 'dS_dV_max_V':'univariate, V_max(dS/dV)', 'dS_dV_min_V':'univariate, V_min(dS/dV)',\\\n",
    "        }, inplace = True)\n",
    "\n",
    "    X_test.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n",
    "                        'dS_dV_area':'univariate, area(dS/dV)', 'dS_dV_max_peak':'univariate, max(dS/dV)', 'dS_dV_min_peak':'univariate, min(dS/dV)',\\\n",
    "                    'dS_dV_peak_diff':'univariate, max(dS/dV) - min(dS/dV)', \\\n",
    "                    'peak V':'univariate, V_max(S)', 'dS_dV_max_V':'univariate, V_max(dS/dV)', 'dS_dV_min_V':'univariate, V_min(dS/dV)',\\\n",
    "        }, inplace = True)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def load_dataset_train_test_splitted(filename):\n",
    "    ML1 = pd.read_excel(f'/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_19_ML1/{filename}.xlsx')\n",
    "    ML2 = pd.read_excel(f'/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_22_ML2/{filename}.xlsx')\n",
    "    ML4 = pd.read_excel(f'/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML4/{filename}.xlsx')\n",
    "\n",
    "    return ML1, ML2, ML4\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86fd754a-af21-45fa-8caf-aa0767167e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML1_noisy_train, ML2_noisy_train, ML4_noisy_train = load_dataset_train_test_splitted('extracted_features_noisy_training_dataset')\n",
    "ML1_train, ML2_train, ML4_train = load_dataset_train_test_splitted('extracted_features_training_dataset')\n",
    "ML1_test, ML2_test, ML4_test = load_dataset_train_test_splitted('extracted_features_training_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b32c931e-777e-498d-8448-7d0626c9da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_propery = 'noiseless'\n",
    "if data_propery=='noisy':\n",
    "    ML1_X_train, ML1_X_test, ML1_y_train, ML1_y_test = normalize_create_training_data(ML1_noisy_train, ML1_test)\n",
    "    ML2_X_train, ML2_X_test, ML2_y_train, ML2_y_test = normalize_create_training_data(ML2_noisy_train, ML2_test)\n",
    "    ML4_X_train, ML4_X_test, ML4_y_train, ML4_y_test = normalize_create_training_data(ML4_noisy_train, ML4_test)\n",
    "    \n",
    "elif data_propery=='both':\n",
    "    ML1_train_combined = pd.concat([ML1_noisy_train, ML1_train])\n",
    "    ML2_train_combined = pd.concat([ML2_noisy_train, ML2_train])\n",
    "    ML4_train_combined = pd.concat([ML4_noisy_train, ML4_train])\n",
    "    \n",
    "    ML1_X_train, ML1_X_test, ML1_y_train, ML1_y_test = normalize_create_training_data(ML1_train_combined, ML1_test)\n",
    "    ML2_X_train, ML2_X_test, ML2_y_train, ML2_y_test = normalize_create_training_data(ML2_train_combined, ML2_test)\n",
    "    ML4_X_train, ML4_X_test, ML4_y_train, ML4_y_test = normalize_create_training_data(ML4_train_combined, ML4_test)\n",
    "    \n",
    "else:\n",
    "    ML1_X_train, ML1_X_test, ML1_y_train, ML1_y_test = normalize_create_training_data(ML1_train, ML1_test)\n",
    "    ML2_X_train, ML2_X_test, ML2_y_train, ML2_y_test = normalize_create_training_data(ML2_train, ML2_test)\n",
    "    ML4_X_train, ML4_X_test, ML4_y_train, ML4_y_test = normalize_create_training_data(ML4_train, ML4_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc1c8d0f-a7ba-416f-aa42-15bd4300ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([ML1_X_train, ML2_X_train, ML4_X_train], axis=0)\n",
    "y_train = pd.concat([ML1_y_train, ML2_y_train, ML4_y_train], axis=0)\n",
    "\n",
    "indx_shuffle = np.random.permutation(range(len(X_train)))\n",
    "X_train      = X_train.iloc[indx_shuffle]\n",
    "y_train      = y_train.iloc[indx_shuffle]\n",
    "\n",
    "X_test  = pd.concat([ML1_X_test,  ML2_X_test,  ML4_X_test], axis=0)\n",
    "y_test  = pd.concat([ML1_y_test,  ML2_y_test,  ML4_y_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5dbe3dd0-b5ed-4b50-9460-1163d0a97334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 13)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8af98296-03cb-45ca-891e-63ce1705a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models\n",
    "models = ['Linear', 'KNN', 'SVM', 'RF', 'GP', 'Ridge', 'Lasso', 'univariate, std(S)', 'univariate, max(dS/dV)']\n",
    "\n",
    "# Calcualte y_LOD\n",
    "y_LOD = 0.9117010154341669 #calculate_y_LOD(X_testing, y_testing)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "r2_score_val,  per_diff_val  = {'Models':[], 'Scores':[]}, {'Models':[], 'Scores':[]}\n",
    "r2_score_test, per_diff_test = {'Models':[], 'Scores':[]}, {'Models':[], 'Scores':[]}\n",
    "\n",
    "for model_name in models:\n",
    "    model      = select_model(model_name)\n",
    "\n",
    "    val_r2     = calculate_r2_score(model, X_train[models_features_r2[model_name]],  y_train, kf)\n",
    "    val_per    = calculate_per_diff(model, X_train[models_features_per[model_name]], y_train, kf, y_LOD)\n",
    "\n",
    "    r2_score_val['Scores'].append(val_r2)\n",
    "    per_diff_val['Scores'].append(val_per)\n",
    "\n",
    "    model_r2  = clone(model)\n",
    "    model_r2.fit(X_train[models_features_r2[model_name]], y_train)\n",
    "    y_pred_r2 = model_r2.predict(X_test[models_features_r2[model_name]])\n",
    "\n",
    "    r2_test_score = r2_score(y_test, y_pred_r2)\n",
    "    adj_r2_test   = find_adj_score(len(y_pred_r2), len(models_features_r2[model_name]), r2_test_score)\n",
    "    \n",
    "    r2_score_test['Scores'].append((r2_test_score, adj_r2_test))\n",
    "\n",
    "    model_per_diff = clone(model)\n",
    "    model_per_diff.fit(X_train[models_features_per[model_name]], y_train)\n",
    "    y_pred_per_diff = model_per_diff.predict(X_test[models_features_per[model_name]])\n",
    "    \n",
    "    per_diff_test['Scores'].append(per_error(y_test, y_pred_per_diff, y_LOD))\n",
    "\n",
    "    r2_score_val['Models'].append(model_name)\n",
    "    per_diff_val['Models'].append(model_name) \n",
    "    r2_score_test['Models'].append(model_name)\n",
    "    per_diff_test['Models'].append(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5dd0cfc4-dc2e-42a0-b7b8-09fb0fd2ae9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "savedir   = f'../results/Noisy_Training_Dataset/data_property_{data_propery}'\n",
    "adj_score = False\n",
    "\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "visualization_testing_dataset(r2_score_val,  f'{savedir}/r2_score_val.png',   model_name_conversion, only_one_multivariate=False, adj_score=adj_score, legends=True)\n",
    "visualization_testing_dataset(per_diff_val, f'{savedir}/per_error_val.png', model_name_conversion, only_one_multivariate=False, r2_score=False, adj_score=False, legends=True)\n",
    "\n",
    "visualization_testing_dataset(r2_score_test,  f'{savedir}/r2_score_test.png',   model_name_conversion, only_one_multivariate=False, adj_score=adj_score, legends=True)\n",
    "visualization_testing_dataset(per_diff_test, f'{savedir}/per_error_test.png', model_name_conversion, only_one_multivariate=False, r2_score=False, adj_score=False, legends=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe3d4d-821c-455d-bb68-2ab30d4c535e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
