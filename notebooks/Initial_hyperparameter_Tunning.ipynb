{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2893c850-c467-4d8d-a236-987c9e6e1a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e656001f-f9a0-4f8e-bce7-ab693d9eb450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import *\n",
    "from src.utils import per_error\n",
    "from src.load_dataset import load_dataset\n",
    "from src.load_models import select_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e4ec76-5669-47d8-98ca-e70e4de03861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x15705f260>\n",
      "######Data Distribution:#########\n",
      "Training {0: 23, 8: 25, 16: 21}\n",
      "Testing {0: 15, 8: 16, 16: 15}\n",
      "#################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangam/Desktop/Epilepsey/Code/vgramreg/src/load_dataset.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "# Load Training Dataset\n",
    "X_train, X_test, y_train, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc9a9a-9c7a-4b4d-bcb1-75964139bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "# Load Training Dataset\n",
    "X_train, X_test, y_train, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "febd6b97-364d-4286-acc6-430603812182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe11625-7f61-4f2e-83c0-4973abd0bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the custom error function to a scorer\n",
    "def per_error(y_test, y_pred)->float:\n",
    "    y_LOD=1.6193237802284837\n",
    "   \n",
    "    mask           = (y_test != 0)    # Non Zero Concentration\n",
    "    zero_mask      = ~(mask)          # Zero Concentration\n",
    "\n",
    "    y_pred         = np.maximum(y_pred, 0.0)\n",
    "\n",
    "    # Only for non zero concentration\n",
    "    non_zero_per_error = np.abs(y_test[mask] - y_pred[mask])/(0.5*(y_test[mask] + y_pred[mask]))\n",
    "   \n",
    "    # zero concentration\n",
    "    zero_per_error     = np.abs(y_test[zero_mask] - y_pred[zero_mask]) / y_LOD\n",
    "\n",
    "    # assert not(np.isnan(zero_per_error).any())\n",
    "    # assert not(np.isnan(non_zero_per_error).any())\n",
    "\n",
    "    per_error         = np.concatenate((non_zero_per_error, zero_per_error))\n",
    "    per_error         = np.mean(per_error) * 100\n",
    "\n",
    "    return per_error\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c63dc3-8cb2-4445-895a-c88f32968638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Score: -19.094092404741474\n",
      "R2 Score 0.858670347025452\n",
      "% error 22.202404478530152\n",
      "******************************************\n",
      "RF\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: -10.437568176781735\n",
      "R2 Score 0.8560558823529412\n",
      "% error 17.05027931822751\n",
      "******************************************\n",
      "KNN\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Best Score: -12.015563001447026\n",
      "R2 Score 0.8565426170468187\n",
      "% error 16.39885099123309\n",
      "******************************************\n",
      "GP\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best Parameters: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}\n",
      "Best Score: -18.154146633552024\n",
      "R2 Score 0.8613458588919708\n",
      "% error 19.441893033912155\n",
      "******************************************\n",
      "Ridge\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Parameters: {'alpha': 0.01}\n",
      "Best Score: -30.9670558984321\n",
      "R2 Score 0.8338682019449355\n",
      "% error 30.969978999239018\n",
      "******************************************\n",
      "Lasso\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Parameters: {'alpha': 0.001}\n",
      "Best Score: -32.22744505473233\n",
      "R2 Score 0.8347268740485678\n",
      "% error 31.075026334565365\n",
      "******************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.473e+01, tolerance: 5.311e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.352e+02, tolerance: 5.051e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.715e-01, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+02, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.405e+01, tolerance: 5.100e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e+02, tolerance: 5.170e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.498e+02, tolerance: 5.100e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.983e+02, tolerance: 5.311e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.710e+02, tolerance: 6.400e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "models = ['SVM', 'RF', 'KNN', 'GP', 'Ridge', 'Lasso']\n",
    "metric = 'per_error'\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grids = {'SVM':{\n",
    "                    'C': [0.1, 1, 10, 100, 200],\n",
    "                    'gamma': [1, 0.1, 0.01, 0.001, 0.0005, 0.0001],\n",
    "                    'kernel': ['rbf']},\n",
    "              \n",
    "              'RF': {\n",
    "                    'n_estimators': [100, 200, 300],\n",
    "                    'max_depth': [None, 10, 20, 30],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 4] \n",
    "                     },\n",
    "              \n",
    "              'KNN': {\n",
    "                        'n_neighbors': [3, 5, 7, 9],\n",
    "                        'weights': ['uniform', 'distance'],\n",
    "                        'metric': ['euclidean', 'manhattan']\n",
    "                    },\n",
    "              \n",
    "              'GP': {'kernel': [1.0 * RBF(length_scale=1.0), 1.0 * RBF(length_scale=0.5), 1.0 * Matern(length_scale=1.0, nu=1.5)]},\n",
    "               'Ridge': {'alpha': [0.001, 0.01, 0.1, 1.0, 1.5, 2.0]},\n",
    "               'Lasso': {'alpha': [0.001, 0.01, 0.1, 1.0, 1.5, 2.0]}\n",
    "              }\n",
    "\n",
    "scorer = make_scorer((r2_score if metric=='r2' else per_error), greater_is_better=(True if metric=='r2' else False))\n",
    "\n",
    "for model_name in models:\n",
    "\n",
    "    print(model_name)\n",
    "    # Create a base model\n",
    "    estimator = select_model(model_name)\n",
    "\n",
    "    param_grid = param_grids[model_name]\n",
    "    \n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1, scoring=scorer)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and best score\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "    # Use the best estimator to make predictions\n",
    "    best_svc = grid_search.best_estimator_\n",
    "    # best_svc.fit(X_train, y_train)\n",
    "    y_pred = best_svc.predict(X_test)\n",
    "    \n",
    "    print(\"R2 Score\",r2_score(y_test, y_pred))\n",
    "    print(\"% error\", per_error(y_test, y_pred))\n",
    "\n",
    "    print(\"******************************************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c383578-a4e7-4123-9e51-ff048d87998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = select_model('SVM')\n",
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0a36b-6cb0-4c07-8494-7bfec3056b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
