{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5186188-ce39-4116-bbf0-e2aab6316fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from src.load_dataset import load_dataset\n",
    "from src.config import *\n",
    "from src.utils import per_error, calculate_r2_score, calculate_per_diff, find_adj_score\n",
    "from src.graph_visualization import visualization_testing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d642c0-faa5-4b4f-adb0-9b7fadb88b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "normalization     = True\n",
    "# Perform normalization\n",
    "standardize_type  = 'mean_std' if normalization else 'none'  # select normalization type (min_max, mean_std)\n",
    "split             = True                                    # Split batch dataset into training and testing set\n",
    "combat_norm       = False                                     # apply combat normalization\n",
    "normalize_blanks  = False\n",
    "test_nor_separate = False\n",
    "\n",
    "if split:\n",
    "    (ML1_X_train, ML1_X_test, ML1_y_train, ML1_y_test), _  = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_19_ML1', normalization=normalization, standardize_type=standardize_type, normalize_blanks=normalize_blanks, test_nor_separate=test_nor_separate, split=split)\n",
    "    (ML2_X_train, ML2_X_test, ML2_y_train, ML2_y_test), _  = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_22_ML2', normalization=normalization, standardize_type=standardize_type, normalize_blanks=normalize_blanks, test_nor_separate=test_nor_separate, split=split)\n",
    "    (ML4_X_train, ML4_X_test, ML4_y_train, ML4_y_test), _  = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML4', normalization=normalization, standardize_type=standardize_type, normalize_blanks=normalize_blanks, test_nor_separate=test_nor_separate, split=split)\n",
    "\n",
    "else:\n",
    "    ML1_X, ML1_y = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_19_ML1', normalization=normalization, standardize_type=standardize_type, split=split)\n",
    "    ML2_X, ML2_y = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_22_ML2', normalization=normalization, standardize_type=standardize_type, split=split)\n",
    "    ML4_X, ML4_y = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML4', normalization=normalization, standardize_type=standardize_type, split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cee50f-8361-4427-a6be-27758b38c2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA and t-SEN\n",
    "if split:\n",
    "    data_train          = pd.concat([ML1_X_train, ML2_X_train, ML4_X_train])\n",
    "    batch_labels_train  = np.repeat(['ML1', 'ML2', 'ML4'], repeats= [len(ML1_X_train), len(ML2_X_train), len(ML4_X_train)])\n",
    "    batch_labels_test   = np.repeat(['ML1', 'ML2', 'ML4'], repeats= [len(ML1_X_test),  len(ML2_X_test),  len(ML4_X_test)])\n",
    "    \n",
    "    labels_train = ML1_y_train.values.tolist() + ML2_y_train.values.tolist() + ML4_y_train.values.tolist()\n",
    "    labels_test  = ML1_y_test.values.tolist()  + ML2_y_test.values.tolist()  + ML4_y_test.values.tolist()\n",
    "    \n",
    "    # tsen_pca_viz([ML1_X_train, ML2_X_train, ML4_X_train], batch_labels_train, labels_train)\n",
    "    # tsen_pca_viz([ML1_X_test,  ML2_X_test,  ML4_X_test],  batch_labels_test,  labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dbac1c-a7a0-4d13-90ac-73cfa0df3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform stratified train test split\n",
    "if split==False:\n",
    "    X                = pd.concat([ML1_X, ML2_X, ML4_X], axis=0)\n",
    "    y                = ML1_y.values.tolist() + ML2_y.values.tolist() + ML4_y.values.tolist()\n",
    "    stratified_label = ML1_y.map(lambda x: f'ML1_{x}').values.tolist() + ML2_y.map(lambda x: f'ML2_{x}').values.tolist() + ML4_y.map(lambda x: f'ML4_{x}').values.tolist()\n",
    "    \n",
    "    X_train, X_test, y_train_strat, y_test_strat = train_test_split(X, stratified_label, test_size=0.4, shuffle=True, random_state=20, stratify=stratified_label)\n",
    "    y_train, y_test = pd.Series(y_train_strat).map(lambda x: eval(x.split('_')[1])), pd.Series(y_test_strat).map(lambda x: eval(x.split('_')[1]))\n",
    "\n",
    "else:\n",
    "    y_train_strat = ML1_y_train.map(lambda x: f'ML1_{x}').values.tolist() + ML2_y_train.map(lambda x: f'ML2_{x}').values.tolist() + ML4_y_train.map(lambda x: f'ML4_{x}').values.tolist()\n",
    "    y_test_strat  = ML1_y_test.map(lambda x: f'ML1_{x}').values.tolist() + ML2_y_test.map(lambda x: f'ML2_{x}').values.tolist() + ML4_y_test.map(lambda x: f'ML4_{x}').values.tolist()\n",
    "\n",
    "    # Combine ML1, ML2, and ML4 dataset\n",
    "    X_train, X_test, y_train, y_test =  pd.concat([ML1_X_train, ML2_X_train, ML4_X_train], axis=0).reset_index(drop=True), \\\n",
    "                                        pd.concat([ML1_X_test,  ML2_X_test,  ML4_X_test],  axis=0).reset_index(drop=True), \\\n",
    "                                        pd.concat([ML1_y_train, ML2_y_train, ML4_y_train], axis=0).reset_index(drop=True), \\\n",
    "                                        pd.concat([ML1_y_test,  ML2_y_test,  ML4_y_test],  axis=0).reset_index(drop=True)\n",
    "\n",
    "    # Create shuffling index with random choice\n",
    "    shuffle_ind_train = np.random.choice(range(len(X_train)), len(X_train), replace=False)\n",
    "    assert len(np.unique(shuffle_ind_train))==len(X_train)\n",
    "    \n",
    "    shuffle_ind_test = np.random.choice(range(len(X_test)), len(X_test), replace=False)\n",
    "    assert len(np.unique(shuffle_ind_test))==len(X_test)\n",
    "\n",
    "    # Shuffle training dataset\n",
    "    X_train, y_train = X_train.iloc[shuffle_ind_train], y_train.iloc[shuffle_ind_train]\n",
    "    X_test,  y_test  = X_test.iloc[shuffle_ind_test],   y_test.iloc[shuffle_ind_test]\n",
    "\n",
    "    # Check if the labels and features have same index after shuffling\n",
    "    assert X_train.index.tolist()==y_train.index.tolist()\n",
    "    assert X_test.index.tolist()==y_test.index.tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4817b-cd95-43bc-983b-4ae75505c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindBestGridSearch(model, features, X_train, y_train, param_grid, metric):\n",
    "\n",
    "    scorer = make_scorer((r2_score if metric=='r2' else per_error), greater_is_better=(True if metric=='r2' else False))\n",
    "    \n",
    "    estimator = clone(model)\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1, scoring=scorer)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train[features], y_train)\n",
    "\n",
    "    # Print the best parameters and best score\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "    # Use the best estimator to make predictions\n",
    "    best_svc = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "    return best_svc, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe7723b-49a1-43c2-8c7b-cefbe5c528e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SVR models with different kernels\n",
    "svr_linear  =  SVR(kernel='linear')\n",
    "svr_poly    =  SVR(kernel='poly', gamma='scale', degree=3, coef0=1)\n",
    "svr_rbf     =  SVR(kernel='rbf',  gamma=0.01, C=100)\n",
    "svr_sigmoid =  SVR(kernel='sigmoid', coef0=1)\n",
    "\n",
    "C_all       = [0.1, 1, 10, 100, 200]\n",
    "coef_all    = [0.1, 0, 1, 2]\n",
    "degrees     = [2, 3, 4]\n",
    "gammas      = [0.01, 0.1, 1, 2]\n",
    "\n",
    "param_grids  = {\n",
    "                'Linear':{'C':C_all},\n",
    "               'Poly':{'coef0': coef_all, 'degree':degrees, 'gamma':gammas, 'C':C_all},\n",
    "               'RBF': {'gamma':gammas, 'C':C_all},\n",
    "               'Sigmoid': {'coef0':coef_all, 'C':C_all}\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c3524-2b86-4b32-b9bf-2f81a0096245",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_LOD = 0.9117010154341669\n",
    "kf    = KFold(n_splits=5)\n",
    "\n",
    "r2_score_val,  per_diff_val  = {'Models':[], 'Scores':[]}, {'Models':[], 'Scores':[]}\n",
    "r2_score_test, per_diff_test = {'Models':[], 'Scores':[]}, {'Models':[], 'Scores':[]}\n",
    "\n",
    "svm_models = [svr_linear, svr_poly, svr_rbf, svr_sigmoid]\n",
    "svm_names  = ['Linear', 'Poly', 'RBF', 'Sigmoid']\n",
    "\n",
    "for model, model_name in zip(svm_models, svm_names):\n",
    "\n",
    "    param_grid = param_grids[model_name]\n",
    "\n",
    "    model_r2, val_r2        = FindBestGridSearch(model, models_features_r2['SVM'],  X_train, y_train, param_grid, metric='r2')\n",
    "    model_per_diff, val_per = FindBestGridSearch(model, models_features_per['SVM'], X_train, y_train, param_grid, metric='per_error')\n",
    "\n",
    "    r2_score_val['Scores'].append(val_r2)\n",
    "    per_diff_val['Scores'].append(val_per)\n",
    "\n",
    "    model_r2.fit(X_train[models_features_r2['SVM']], y_train)\n",
    "    y_pred_r2 = model_r2.predict(X_test[models_features_r2['SVM']])\n",
    "\n",
    "    r2_test_score = r2_score(y_test, y_pred_r2)\n",
    "    adj_r2_test   = find_adj_score(len(y_pred_r2), len(models_features_r2['SVM']), r2_test_score)\n",
    "    \n",
    "    r2_score_test['Scores'].append((r2_test_score, adj_r2_test))\n",
    "\n",
    "    model_per_diff.fit(X_train[models_features_per['SVM']], y_train)\n",
    "    y_pred_per_diff = model_per_diff.predict(X_test[models_features_per['SVM']])\n",
    "    \n",
    "    per_diff_test['Scores'].append(per_error(y_test, y_pred_per_diff, y_LOD))\n",
    "\n",
    "    r2_score_val['Models'].append(model_name)\n",
    "    per_diff_val['Models'].append(model_name) \n",
    "    r2_score_test['Models'].append(model_name)\n",
    "    per_diff_test['Models'].append(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86aac3-ef76-4fda-a7ab-8b6b7437e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir   = f'../results/RandomForest_Kernel_Selection'\n",
    "adj_score = False\n",
    "\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "visualization_testing_dataset(r2_score_val,  f'{savedir}/r2_score_val.png',   model_name_conversion, only_one_multivariate=False, adj_score=adj_score, legends=True)\n",
    "visualization_testing_dataset(per_diff_val, f'{savedir}/per_error_val.png', model_name_conversion, only_one_multivariate=False, r2_score=False, adj_score=False, legends=True)\n",
    "\n",
    "visualization_testing_dataset(r2_score_test,  f'{savedir}/r2_score_test.png',   model_name_conversion, only_one_multivariate=False, adj_score=adj_score, legends=True)\n",
    "visualization_testing_dataset(per_diff_test, f'{savedir}/per_error_test.png', model_name_conversion, only_one_multivariate=False, r2_score=False, adj_score=False, legends=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d3b8d-9351-461e-8f23-8df05adac4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
