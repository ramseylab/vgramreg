{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5663283-9384-43f6-921e-c832d1b9e5c7",
   "metadata": {},
   "source": [
    "## Following experiments are being performed in this notebook\n",
    " 1) Use Features extracted from ML12\n",
    " 2) Training ML12\n",
    " 3) Check the generability when ML12 is normalized with only the blanks and ML4 is normalized only with the blanks\n",
    " 4) Testing 5 fold <br>\n",
    "        -> Calculate the variance and mean only from 4 folds (only from the blanks) and test on 1 fold <br>\n",
    "\t\t-> Repeat for every fold.\n",
    "\n",
    "## Blank feature comparison between ML12 and ML4\n",
    "```\n",
    "                                        Mean ML12         ML4\n",
    " univariate, area(S)                     0.625470         0.338291\n",
    " peak curvature                         35.631810         36.161643\n",
    " univariate, V_max(S)                    1.012192         1.007822\n",
    " vcenter                                 1.015360         1.016870\n",
    " univariate, max(S)                      0.008779         0.006264\n",
    " univariate, mean(S)                     0.000892         0.000487\n",
    " univariate, std(S)                      0.002334         0.002030\n",
    " univariate, max(dS/dV)                  0.296886         0.307639\n",
    " univariate, min(dS/dV)                 -0.284828         -0.265513\n",
    " univariate, max(dS/dV) - min(dS/dV)     0.581714         0.573135       \n",
    " univariate, V_max(dS/dV)                0.981520         0.998957\n",
    " univariate, V_min(dS/dV)                1.045040         1.025391\n",
    " univariate, area(dS/dV)                 0.017548         0.012530\n",
    "```\n",
    "\n",
    "The difference between the two different dataset for blank is close\n",
    "\n",
    "## label 8 feature comparison between ML12 and ML4\n",
    "```\n",
    "                                        Mean ML12        Mean ML4\n",
    " univariate, area(S)                     3.544772        7.607660\n",
    " peak curvature                         80.466083        192.092580\n",
    " univariate, V_max(S)                    1.056402        1.048924\n",
    " vcenter                                 1.056426        1.050648\n",
    " univariate, max(S)                      0.054969        0.122838\n",
    " univariate, mean(S)                     0.005053        0.010868\n",
    " univariate, std(S)                      0.013428        0.029184\n",
    " univariate, max(dS/dV)                  1.221215        2.677500\n",
    " univariate, min(dS/dV)                 -1.391168        -3.465284\n",
    " univariate, max(dS/dV) - min(dS/dV)     2.612391        6.142800\n",
    " univariate, V_max(dS/dV)                1.025362        1.021280\n",
    " univariate, V_min(dS/dV)                1.080255        1.075200\n",
    " univariate, area(dS/dV)                 0.109943        0.245688\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3687771c-df07-453c-8dbb-492e5a7cb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "from src.load_models import select_model\n",
    "from src.load_dataset import load_dataset, select_normalizer\n",
    "from src.config import models_features_r2, models_features_per, model_name_conversion\n",
    "from src.graph_visualization import visualize_highest_score_feature_selection, feature_selection_tabularize, visualization_testing_dataset\n",
    "\n",
    "from src.utils import find_adj_score, calculate_y_LOD, per_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01038b8-3206-4225-8f6c-e596b1eab9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x28f8a18c0>\n",
      "######Data Distribution:#########\n",
      "Training {0: 50, 16: 50, 8: 47}\n",
      "Testing {0: 34, 8: 31, 16: 34}\n",
      "#################################\n",
      "######Data Distribution:#########\n",
      "Training {0: 23, 8: 25, 16: 21}\n",
      "Testing {0: 15, 8: 16, 16: 15}\n",
      "#################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangam/Desktop/Epilepsey/Code/vgramreg/src/load_dataset.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n",
      "/Users/sangam/Desktop/Epilepsey/Code/vgramreg/src/load_dataset.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n"
     ]
    }
   ],
   "source": [
    "# Load Training Dataset\n",
    "normalize_blanks   = False\n",
    "normalization      = False\n",
    "use_training_scale = False\n",
    "standardize_type   = ''\n",
    "\n",
    "%matplotlib\n",
    "(X_train, X_test, y_train, y_test), scaler_trainer      = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/ML1_ML2', normalization= normalization, \n",
    "                                                        normalize_blanks=normalize_blanks, standardize_type=standardize_type)\n",
    "(X_train_4, X_test_4, y_train_4, y_test_4), scaler_4    = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/ML4', normalization=False, normalize_blanks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d304987-cf1f-416e-a6d1-82f873de659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "X_4, y_4 = pd.concat([X_train_4, X_test_4], axis=0), pd.concat([y_train_4, y_test_4], axis=0)\n",
    "X, y     = pd.concat([X_train, X_test], axis=0), pd.concat([y_train, y_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31c3245-02e7-4750-aa44-53068ea6dbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_LOD 0.9117010154341676\n"
     ]
    }
   ],
   "source": [
    "models = ['Linear', 'KNN', 'SVM', 'RF', 'GP', 'Ridge', 'Lasso', 'univariate, std(S)', 'univariate, max(dS/dV)', 'univariate, area(dS/dV)', 'univariate, area(S)', 'univariate, max(S)']\n",
    "metric = 'per_error'\n",
    "nor_with_blank = False\n",
    "\n",
    "scorer = make_scorer((r2_score if metric=='r2' else per_error), greater_is_better=(True if metric=='r2' else False))\n",
    "\n",
    "score_dict_r2 = {'Models': [],\n",
    "              'Scores': []}\n",
    "\n",
    "score_dict_per = {'Models': [],\n",
    "              'Scores': []}\n",
    "\n",
    "\n",
    "training_dataset = 'ML12'\n",
    "testing_dataset  = 'ML4'\n",
    "\n",
    "X_training, y_training, X_testing, y_testing = (X, y, X_4, y_4) if training_dataset=='ML12' else (X_4, y_4, X, y)\n",
    "\n",
    "# Calcualte y_LOD\n",
    "y_LOD = calculate_y_LOD(X_testing, y_testing)\n",
    "print(\"y_LOD\", y_LOD)\n",
    "\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b04b4c1-6633-45f6-8121-d994f6748d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Models': ['Linear',\n",
       "   'KNN',\n",
       "   'SVM',\n",
       "   'RF',\n",
       "   'GP',\n",
       "   'Ridge',\n",
       "   'Lasso',\n",
       "   'univariate, std(S)',\n",
       "   'univariate, max(dS/dV)',\n",
       "   'univariate, area(dS/dV)',\n",
       "   'univariate, area(S)',\n",
       "   'univariate, max(S)'],\n",
       "  'Scores': [(0.18823781584456145, 0.15100101840623859),\n",
       "   (0.4611366766316214, 0.4415416466909531),\n",
       "   (0.41225797998552294, 0.37380756746121135),\n",
       "   (0.4776878862033582, 0.4683608841712753),\n",
       "   (-0.26479029762760153, -0.27598313211988135),\n",
       "   (-0.25905667247478936, -0.3414248660011776),\n",
       "   (-0.5776123040535401, -0.6499798409367301),\n",
       "   (-1.5347043089922816, -1.557135320576284),\n",
       "   (-1.703851087991513, -1.7277789737259512),\n",
       "   (-1.566691763603365, -1.5894058500069344),\n",
       "   (-1.0840249423417538, -1.1024676409465481),\n",
       "   (-1.5664074568001194, -1.5891190272142799)]},\n",
       " {'Models': ['Linear',\n",
       "   'KNN',\n",
       "   'SVM',\n",
       "   'RF',\n",
       "   'GP',\n",
       "   'Ridge',\n",
       "   'Lasso',\n",
       "   'univariate, std(S)',\n",
       "   'univariate, max(dS/dV)',\n",
       "   'univariate, area(dS/dV)',\n",
       "   'univariate, area(S)',\n",
       "   'univariate, max(S)'],\n",
       "  'Scores': [78.54990084291519,\n",
       "   35.01585966539037,\n",
       "   38.324676545692924,\n",
       "   36.01077421116684,\n",
       "   133.91304347826087,\n",
       "   104.70848747114032,\n",
       "   88.80564518116586,\n",
       "   92.82710449660514,\n",
       "   113.52924402142435,\n",
       "   94.36700707898808,\n",
       "   88.7108177552806,\n",
       "   94.36316403063934]})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name in models:\n",
    "\n",
    "    # Test for R2 score\n",
    "    model    = select_model(model_name)\n",
    "\n",
    "    model_r2  = clone(model)\n",
    "    model_per = clone(model)\n",
    "\n",
    "    model_r2.fit(X_training[models_features_r2[model_name]],   y_training)                 # Fit model with R2 features on ML1_2 dataset\n",
    "    model_per.fit(X_training[models_features_per[model_name]], y_training)                 # Fit percent error with R2 features on ML1_2 dataset\n",
    "    \n",
    "    y_pred_r2  = []\n",
    "    y_pred_per = []\n",
    "    y_gt       = []\n",
    "    \n",
    "    for train_ind, test_ind in kf.split(X_testing):\n",
    "        # Features\n",
    "        X_train_temp = X_testing.iloc[train_ind].copy()\n",
    "        X_test_temp  = X_testing.iloc[test_ind].copy()\n",
    "\n",
    "        # labels\n",
    "        y_train_temp = X_testing.to_numpy()[train_ind].copy()\n",
    "        y_test_temp  = y_testing.to_numpy()[test_ind].copy()\n",
    "\n",
    "\n",
    "        if normalization==True:\n",
    "            if use_training_scale: scaler     = scaler_trainer\n",
    "    \n",
    "            else:\n",
    "                scaler = select_normalizer(standardize_type)\n",
    "                if normalize_blanks: scaler.fit(X_train_temp[y_train_temp==0])\n",
    "        \n",
    "                # Fit the scaler to the training dataset\n",
    "                else: scaler.fit(X_train_temp)                       # Calculate mean and standard deviation only on the four folds\n",
    "            \n",
    "            X_test_temp = scaler.transform(X_test_temp)    # Normalize the remaining validation fold\n",
    "            X_test_temp = pd.DataFrame(X_test_temp, columns=X_testing.columns)\n",
    " \n",
    "        \n",
    "        y_pred_r2  += model_r2.predict(X_test_temp[models_features_r2[model_name]]).tolist()      # Inference model with R2 features on ML4 dataset\n",
    "        y_pred_per += model_per.predict(X_test_temp[models_features_per[model_name]]).tolist()    # Inference percent error features on ML4 dataset\n",
    "\n",
    "        y_gt       += y_test_temp.tolist()\n",
    "  \n",
    "    r2Score      = r2_score(y_gt, y_pred_r2)\n",
    "    adj_r2_Score = find_adj_score(len(y_gt), len(models_features_r2[model_name]), r2Score)\n",
    "\n",
    "    score_dict_r2['Models'].append(model_name)\n",
    "    score_dict_per['Models'].append(model_name)\n",
    "    \n",
    "    score_dict_r2['Scores'].append((r2Score, adj_r2_Score))\n",
    "    score_dict_per['Scores'].append(per_error(pd.Series(y_gt), y_pred_per, y_LOD=y_LOD))\n",
    "\n",
    "score_dict_r2, score_dict_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8edf3f0b-8de5-4e1b-b26f-c9bab24527c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir      = 'Generability_output_diff_mean_std'\n",
    "r2_savefile  = f'{savedir}/r2_score_D_{training_dataset}_T_{testing_dataset}_sTrain_{use_training_scale}_nBlank_{normalize_blanks}_nType_{standardize_type}.png'\n",
    "per_savefile = f'{savedir}/per_error_score_D_{training_dataset}_T_{testing_dataset}_sTrain_{use_training_scale}_nBlank_{normalize_blanks}_nType_{standardize_type}.png'\n",
    "\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "visualization_testing_dataset(score_dict_r2,  r2_savefile,  model_name_conversion, only_one_multivariate=False, adj_score=True, legends=True)\n",
    "visualization_testing_dataset(score_dict_per, per_savefile, model_name_conversion, only_one_multivariate=False, r2_score=False, adj_score=False, legends=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb67a6d7-11d3-456c-8d67-ad468cf79c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715293f7-175f-4a16-9719-a8701977aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_temp==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348474fc-fbdb-49ba-8903-d268ea3321fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
