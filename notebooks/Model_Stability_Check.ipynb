{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7f811f-9a51-4a9a-bd06-d55a3b120ced",
   "metadata": {},
   "source": [
    "## Test the Stability of the Model\n",
    "In this experiment, we check the stability of the model by performing the following experiments: \n",
    "1. Remove 5% - 10% of data randomly from the training set and evaluate the testing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16782538-da1b-4fc2-ae06-f6ff3e080ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from src.load_dataset import load_dataset\n",
    "from src.utils import tsen_pca_viz, verify_batch_label_dist, calculate_r2_score, calculate_per_diff, per_error, find_adj_score, perform_combat_normalization\n",
    "from src.load_models import select_model\n",
    "from src.graph_visualization import visualization_testing_dataset\n",
    "from src.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f916110f-ec28-48e9-b5ba-76c4ae5a46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "normalization    = True\n",
    "standardize_type = 'mean_std' if normalization else 'none'\n",
    "split            = False\n",
    "combat_norm      = True\n",
    "data_per_remove  = 5\n",
    "\n",
    "ML1_X, ML1_y = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_19_ML1', normalization=normalization, standardize_type=standardize_type, split=split)\n",
    "ML2_X, ML2_y = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_22_ML2', normalization=normalization, standardize_type=standardize_type, split=split)\n",
    "ML4_X, ML4_y = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML4', normalization=normalization, standardize_type=standardize_type, split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c14831-0897-49ad-bbf4-3b3f38980cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stratified train test split\n",
    "X                = pd.concat([ML1_X, ML2_X, ML4_X], axis=0)\n",
    "y                = ML1_y.values.tolist() + ML2_y.values.tolist() + ML4_y.values.tolist()\n",
    "stratified_label = ML1_y.map(lambda x: f'ML1_{x}').values.tolist() + ML2_y.map(lambda x: f'ML2_{x}').values.tolist() + ML4_y.map(lambda x: f'ML4_{x}').values.tolist()\n",
    "\n",
    "X_train, X_test, y_train_strat, y_test_strat = train_test_split(X, stratified_label, test_size=0.4, shuffle=True, random_state=20, stratify=stratified_label)\n",
    "y_train, y_test = pd.Series(y_train_strat).map(lambda x: eval(x.split('_')[1])), pd.Series(y_test_strat).map(lambda x: eval(x.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dcd4d4-576b-4f62-8f0b-240a657299f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores_distribution(scores, model_name):\n",
    "    scores = scores.copy()\n",
    "    if type(scores[5][model_name][0])==tuple:\n",
    "        for data_per_remove in per_to_remove:\n",
    "            scores[data_per_remove][model_name] = np.array(scores[data_per_remove][model_name])[:,0]\n",
    "    for data_per_remove in per_to_remove:\n",
    "        sns.kdeplot(scores[data_per_remove][model_name], label=f'{data_per_remove}%')\n",
    "    \n",
    "    plt.legend(title='Parameter', title_fontsize='13')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def training_reduction_plot(scores, model_names, r2=True):\n",
    "    \n",
    "\n",
    "    min_, max_ = (0.70 if r2 else 10), (0.9 if r2 else 60)\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        data = []\n",
    "        if type(scores[5][model_name][0])==tuple:\n",
    "            for data_per_remove in per_to_remove:\n",
    "                scores[data_per_remove][model_name] = np.array(scores[data_per_remove][model_name])[:,0]\n",
    "    \n",
    "        for data_per_remove in per_to_remove:\n",
    "            data.append(scores[data_per_remove][model_name].mean())\n",
    "            \n",
    "        # plt.ylim(bottom=min_, top=max_)\n",
    "        plt.plot(data, label=model_name)\n",
    "        plt.xticks(ticks=[0, 1, 2, 3], labels=[f'{i}%' for i in per_to_remove])\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "def box_plot(scores):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c69ffa-57ec-4e68-9431-35e9e723651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models\n",
    "models        = ['Linear', 'KNN', 'SVM', 'RF', 'GP', 'Ridge', 'Lasso', 'univariate, std(S)', 'univariate, max(dS/dV)', 'univariate, area(dS/dV)', 'univariate, area(S)', 'univariate, max(S)']\n",
    "per_to_remove = [5, 10, 20, 30, 50]\n",
    "num_iteration = 100\n",
    "\n",
    "# Calcualte y_LOD\n",
    "y_LOD = 0.9117010154341669 #calculate_y_LOD(X_testing, y_testing)\n",
    "#print(\"y_LOD\", y_LOD)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "r2_score_val,  per_diff_val  = {}, {}\n",
    "r2_score_test, per_diff_test = {}, {}\n",
    "\n",
    "for data_per_remove in per_to_remove:\n",
    "    r2_score_val[data_per_remove], per_diff_val[data_per_remove], r2_score_test[data_per_remove], per_diff_test[data_per_remove] = {}, {}, {}, {} \n",
    "    for model_name in models:\n",
    "        r2_score_val[data_per_remove][model_name]  = []\n",
    "        per_diff_val[data_per_remove][model_name]  = [] \n",
    "        r2_score_test[data_per_remove][model_name] = [] \n",
    "        per_diff_test[data_per_remove][model_name] = [] \n",
    "         \n",
    "for data_per_remove in per_to_remove:\n",
    "    for _ in range(num_iteration):\n",
    "        num_selection = int((100 - data_per_remove) * len(y_train) / 100.0)\n",
    "        selected_indx = np.random.choice(range(len(y_train) - 1), num_selection)\n",
    "        \n",
    "        X_train_      = X_train.iloc[selected_indx]\n",
    "        y_train_      = y_train.iloc[selected_indx]\n",
    "    \n",
    "        assert len(y_train_) == num_selection\n",
    "    \n",
    "        print(X_train_.shape)\n",
    "        \n",
    "        for model_name in models:\n",
    "            model    = select_model(model_name)\n",
    "        \n",
    "            val_r2     = calculate_r2_score(model, X_train_[models_features_r2[model_name]],  y_train_, kf)\n",
    "            val_per    = calculate_per_diff(model, X_train_[models_features_per[model_name]], y_train_, kf, y_LOD)\n",
    "        \n",
    "            r2_score_val[data_per_remove][model_name].append((float(val_r2[0]), float(val_r2[1])))\n",
    "            per_diff_val[data_per_remove][model_name].append(float(val_per))\n",
    "        \n",
    "            model_r2  = clone(model)\n",
    "            model_r2.fit(X_train_[models_features_r2[model_name]], y_train_)\n",
    "            y_pred_r2 = model_r2.predict(X_test[models_features_r2[model_name]])\n",
    "        \n",
    "            r2_test_score = r2_score(y_test, y_pred_r2)\n",
    "            adj_r2_test   = find_adj_score(len(y_pred_r2), len(models_features_r2[model_name]), r2_test_score)\n",
    "            \n",
    "            r2_score_test[data_per_remove][model_name].append((float(r2_test_score), float(adj_r2_test)))\n",
    "        \n",
    "            model_per_diff = clone(model)\n",
    "            model_per_diff.fit(X_train_[models_features_per[model_name]], y_train_)\n",
    "            y_pred_per_diff = model_per_diff.predict(X_test[models_features_per[model_name]])\n",
    "            \n",
    "            per_diff_test[data_per_remove][model_name].append(per_error(y_test, y_pred_per_diff, y_LOD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be49575-1ad5-425e-b19e-0a7bd7e09eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_reduction_plot(r2_score_val.copy(), ['Linear', 'SVM', 'RF', 'KNN', 'GP'])\n",
    "training_reduction_plot(r2_score_test.copy(), ['Linear', 'SVM', 'RF', 'KNN', 'GP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e0e46-f9dc-45ba-8d58-266054787e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_reduction_plot(r2_score_val.copy(), ['Linear', 'SVM', 'RF', 'KNN', 'GP'])\n",
    "training_reduction_plot(r2_score_test.copy(), ['Linear', 'SVM', 'RF', 'KNN', 'GP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c51e4-16a5-44d4-8e1b-b9e7e922d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores_distribution(r2_score_test.copy(), 'GP')\n",
    "# plot_scores_distribution(r2_score_val.copy(), 'SVM')\n",
    "# plot_scores_distribution(r2_score_val.copy(), 'RF')\n",
    "# plot_scores_distribution(r2_score_val.copy(), 'KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa07700-c133-45d0-845c-560b3f58eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot KDEs with labels\n",
    "model_name = 'RF'\n",
    "sns.kdeplot(np.array(r2_score_test[5][model_name])[:,0], label='5%', color='r')\n",
    "sns.kdeplot(np.array(r2_score_test[10][model_name])[:,0], label='10%', color='b')\n",
    "sns.kdeplot(np.array(r2_score_test[20][model_name])[:,0], label='20%', color='g')\n",
    "sns.kdeplot(np.array(r2_score_test[30][model_name])[:,0], label='30%', color='m')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Parameter', title_fontsize='13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b131c-ea34-4afd-882f-766956598c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(per_diff_test[5]['KNN'])\n",
    "sns.kdeplot(per_diff_test[10]['Linear'])\n",
    "sns.kdeplot(per_diff_test[20]['Linear'])\n",
    "sns.kdeplot(per_diff_test[30]['Linear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646431e2-53e4-407a-abe8-702ff63c5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabfab21-a543-41cd-ae75-9b4bcb00653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_score_val,  per_diff_val  = {}, {}\n",
    "# r2_score_test, per_diff_test\n",
    "with open('r2_score_val.pickle', 'wb') as f:\n",
    "    dump(r2_score_val, f)\n",
    "\n",
    "with open('per_diff_val.pickle', 'wb') as f:\n",
    "    dump(per_diff_val, f)\n",
    "\n",
    "with open('r2_score_test.pickle', 'wb') as f:\n",
    "    dump(r2_score_test, f)\n",
    "\n",
    "with open('per_diff_test.pickle', 'wb') as f:\n",
    "    dump(per_diff_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9498ddc7-b159-4b64-b039-816ff6bc8fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
