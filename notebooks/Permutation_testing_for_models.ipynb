{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60bf6693-9201-488d-ac70-6cb6daa03ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.permutation_test import pair_permutation_test\n",
    "\n",
    "from glob import glob\n",
    "from pickle import load, dump\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.config import models_features_per\n",
    "from src.utils import per_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "804577f3-a4e1-4697-ade0-a69d8d4a6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_create_training_data(train, test, blank_norm=False, remove_outlier=None):\n",
    "\n",
    "    # Remove outlier only from the training dataset\n",
    "    if remove_outlier=='all':\n",
    "        train = train[train['file'].apply(lambda x: False if (x.split('/')[-1].replace('.txt', '') in ouliners_to_remove) else True)]\n",
    "        test  = test[test['file'].apply(lambda x: False if (x.split('/')[-1].replace('.txt', '') in ouliners_to_remove) else True)]\n",
    "\n",
    "    elif remove_outlier=='train_only':\n",
    "        train = train[train['file'].apply(lambda x: False if (x.split('/')[-1].replace('.txt', '') in ouliners_to_remove) else True)]\n",
    "        \n",
    "    train = train.reset_index(drop=True)\n",
    "    test  = test.reset_index(drop=True)\n",
    "    \n",
    "    X_train = train.drop(columns=['file']).copy()\n",
    "    X_test  = test.drop(columns=['file']).copy()\n",
    "\n",
    "    columns       = X_train.columns\n",
    "    \n",
    "    y_train = train['file'].apply(lambda x: int(x.split('_')[-2].replace('cbz','')))\n",
    "    y_test  = test['file'].apply(lambda x: int(x.split('_')[-2].replace('cbz','')))\n",
    "\n",
    "    assert (X_train.index.values == y_train.index.values).all()\n",
    "\n",
    "    scaler  = StandardScaler()\n",
    "\n",
    "    if blank_norm: scaler.fit(X_train[y_train==0])\n",
    "    else: scaler.fit(X_train)\n",
    "\n",
    "    \n",
    "    X_train = pd.DataFrame(scaler.transform(X_train), columns=columns)\n",
    "    X_test  = pd.DataFrame(scaler.transform(X_test),  columns=columns)\n",
    "\n",
    "    X_train.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n",
    "                        'dS_dV_area':'univariate, area(dS/dV)', 'dS_dV_max_peak':'univariate, max(dS/dV)', 'dS_dV_min_peak':'univariate, min(dS/dV)',\\\n",
    "                    'dS_dV_peak_diff':'univariate, max(dS/dV) - min(dS/dV)', \\\n",
    "                    'peak V':'univariate, V_max(S)', 'dS_dV_max_V':'univariate, V_max(dS/dV)', 'dS_dV_min_V':'univariate, V_min(dS/dV)',\\\n",
    "        }, inplace = True)\n",
    "\n",
    "    X_test.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n",
    "                        'dS_dV_area':'univariate, area(dS/dV)', 'dS_dV_max_peak':'univariate, max(dS/dV)', 'dS_dV_min_peak':'univariate, min(dS/dV)',\\\n",
    "                    'dS_dV_peak_diff':'univariate, max(dS/dV) - min(dS/dV)', \\\n",
    "                    'peak V':'univariate, V_max(S)', 'dS_dV_max_V':'univariate, V_max(dS/dV)', 'dS_dV_min_V':'univariate, V_min(dS/dV)',\\\n",
    "        }, inplace = True)\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test), scaler\n",
    "\n",
    "def load_dataset_train_test_splitted(filename):\n",
    "    ML1 = pd.read_excel(f'/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_19_ML1/{filename}.xlsx')\n",
    "    ML2 = pd.read_excel(f'/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_22_ML2/{filename}.xlsx')\n",
    "    ML4 = pd.read_excel(f'/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML4/{filename}.xlsx')\n",
    "\n",
    "    return ML1, ML2, ML4\n",
    "\n",
    "def load_combined_dataset(data_propery, blank_norm=False, remove_outlier=None):\n",
    "    # Dataset Preparation\n",
    "    if data_propery=='noisy':\n",
    "        (ML1_X_train, ML1_X_test, ML1_y_train, ML1_y_test), ML1_scalar = normalize_create_training_data(ML1_noisy_train, ML1_test, blank_norm, remove_outlier)\n",
    "        (ML2_X_train, ML2_X_test, ML2_y_train, ML2_y_test), ML2_scalar = normalize_create_training_data(ML2_noisy_train, ML2_test, blank_norm, remove_outlier)\n",
    "        (ML4_X_train, ML4_X_test, ML4_y_train, ML4_y_test), ML4_scalar = normalize_create_training_data(ML4_noisy_train, ML4_test, blank_norm, remove_outlier)\n",
    "        \n",
    "    elif data_propery=='augmentation':\n",
    "        ML1_train_combined = pd.concat([ML1_noisy_train, ML1_train])\n",
    "        ML2_train_combined = pd.concat([ML2_noisy_train, ML2_train])\n",
    "        ML4_train_combined = pd.concat([ML4_noisy_train, ML4_train])\n",
    "        \n",
    "        (ML1_X_train, ML1_X_test, ML1_y_train, ML1_y_test), ML1_scalar = normalize_create_training_data(ML1_train_combined, ML1_test, blank_norm, remove_outlier)\n",
    "        (ML2_X_train, ML2_X_test, ML2_y_train, ML2_y_test), ML2_scalar = normalize_create_training_data(ML2_train_combined, ML2_test, blank_norm, remove_outlier)\n",
    "        (ML4_X_train, ML4_X_test, ML4_y_train, ML4_y_test), ML4_scalar = normalize_create_training_data(ML4_train_combined, ML4_test, blank_norm, remove_outlier)\n",
    "        \n",
    "    else:\n",
    "        (ML1_X_train, ML1_X_test, ML1_y_train, ML1_y_test), ML1_scalar = normalize_create_training_data(ML1_train, ML1_test, blank_norm, remove_outlier)\n",
    "        (ML2_X_train, ML2_X_test, ML2_y_train, ML2_y_test), ML2_scalar = normalize_create_training_data(ML2_train, ML2_test, blank_norm, remove_outlier)\n",
    "        (ML4_X_train, ML4_X_test, ML4_y_train, ML4_y_test), ML4_scalar = normalize_create_training_data(ML4_train, ML4_test, blank_norm, remove_outlier)\n",
    "    \n",
    "    \n",
    "    X_train = pd.concat([ML1_X_train, ML2_X_train, ML4_X_train], axis=0)\n",
    "    y_train = pd.concat([ML1_y_train, ML2_y_train, ML4_y_train], axis=0)\n",
    "    \n",
    "    indx_shuffle = np.random.permutation(range(len(X_train)))\n",
    "    X_train      = X_train.iloc[indx_shuffle]\n",
    "    y_train      = y_train.iloc[indx_shuffle]\n",
    "    \n",
    "    X_test  = pd.concat([ML1_X_test,  ML2_X_test,  ML4_X_test], axis=0)\n",
    "    y_test  = pd.concat([ML1_y_test,  ML2_y_test,  ML4_y_test], axis=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f04f0fa-81b5-4b01-9369-0a8063cf530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML1_noisy_train, ML2_noisy_train, ML4_noisy_train = load_dataset_train_test_splitted('extracted_features_noisy_training_dataset')\n",
    "ML1_train, ML2_train, ML4_train = load_dataset_train_test_splitted('extracted_features_training_dataset')\n",
    "ML1_test, ML2_test, ML4_test = load_dataset_train_test_splitted('extracted_features_testing_dataset')\n",
    "\n",
    "# Test if training and testing has common dataset\n",
    "assert len(set(ML1_train['file'].values.tolist()) & set(ML1_test['file'].values.tolist()))==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "895abda7-f4c8-445d-8036-795027b82d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_test, _, y_test = load_combined_dataset(data_propery='noiseless', blank_norm=False, remove_outlier=None)\n",
    "_, X_test_aug, _, y_test_aug = load_combined_dataset(data_propery='augmentation', blank_norm=False, remove_outlier=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b933646c-0eca-4a98-8615-a3ba0ecb14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root_path = os.path.realpath('../models')\n",
    "\n",
    "model_1_path  = os.path.join(model_root_path, 'Data_augmentation_outlier_remove_None')\n",
    "model_2_path  = os.path.join(model_root_path, 'Data_augmentation_outlier_remove_train_only')\n",
    "\n",
    "models_1      =  glob(f'{model_1_path}/*.pickle')\n",
    "models_2      =  glob(f'{model_2_path}/*.pickle')\n",
    "\n",
    "common_models = set([os.path.basename(i) for i in models_1]) & set([os.path.basename(i) for i in models_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38e46fd6-4f35-474d-89d2-bbb668089dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                      | 0/5 [00:00<?, ?it/s]/var/folders/6p/0ctyq1md3qqbfn509nf4xfgr0000gp/T/ipykernel_95068/709678952.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  permutation_test_results = pd.concat([permutation_test_results, temp], axis=0)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:31<00:00,  6.22s/it]\n"
     ]
    }
   ],
   "source": [
    "permutation_test_results = pd.DataFrame(columns=['Comp Models', '1st model (% error)', '2nd model (% error)', '% error Diff', 'p value' ])\n",
    "y_LOD = 0.9117010154341669\n",
    "\n",
    "compare_same_model_with_aug_nor = False\n",
    "\n",
    "for model_file_name in tqdm(common_models):\n",
    "    model_name = model_file_name.replace('.pickle', '')\n",
    "    \n",
    "    with open(os.path.join(model_1_path, model_file_name), 'rb') as f:\n",
    "        model_1 = load(f)\n",
    "\n",
    "    with open(os.path.join(model_2_path, model_file_name), 'rb') as f:\n",
    "            model_2 = load(f)\n",
    "\n",
    "    if not(compare_same_model_with_aug_nor):\n",
    "        if 'augmentation' in model_1_path:\n",
    "            model1_pred = model_1.predict(X_test_aug[models_features_per[model_name]])\n",
    "        else:\n",
    "            model1_pred = model_1.predict(X_test[models_features_per[model_name]])\n",
    "            \n",
    "        if 'augmentation' in model_2_path:\n",
    "            model2_pred = model_2.predict(X_test_aug[models_features_per[model_name]])\n",
    "        else:\n",
    "            model2_pred = model_2.predict(X_test[models_features_per[model_name]])\n",
    "    \n",
    "    else:\n",
    "        model1_pred = model_1.predict(X_test[models_features_per[model_name]])\n",
    "        model2_pred = model_1.predict(X_test_aug[models_features_per[model_name]])\n",
    "\n",
    "    per_error_m1 = per_error(y_test, model1_pred, y_LOD)\n",
    "    per_error_m2 = per_error(y_test, model2_pred, y_LOD)\n",
    "\n",
    "    observed_r2_score, observed_statistic, p_value, _, _ = pair_permutation_test(model1_pred, model2_pred, y_test, y_LOD)\n",
    "    temp = pd.DataFrame({'Comp Models':[f'({model_name}) With | Without Outliers'], '1st model (% error)':per_error_m1, '2nd model (% error)':per_error_m2, '% error Diff':[observed_statistic], 'p value':[p_value]})\n",
    "\n",
    "    permutation_test_results = pd.concat([permutation_test_results, temp], axis=0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68d140d9-260d-4a3a-b942-136ce69e474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loc = '../results/permuation_test/'\n",
    "os.makedirs(save_loc, exist_ok=True)\n",
    "permutation_test_results.to_excel(f'{save_loc}/with_without_augmentation_outliers.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c06fbca6-b25c-4009-a6c2-f37292dbae3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp Models</th>\n",
       "      <th>1st model (% error)</th>\n",
       "      <th>2nd model (% error)</th>\n",
       "      <th>% error Diff</th>\n",
       "      <th>p value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(KNN) With | Without Outliers</td>\n",
       "      <td>21.870328</td>\n",
       "      <td>19.533164</td>\n",
       "      <td>2.337163</td>\n",
       "      <td>0.0184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(GP) With | Without Outliers</td>\n",
       "      <td>25.018578</td>\n",
       "      <td>22.502367</td>\n",
       "      <td>2.516210</td>\n",
       "      <td>0.0516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(RF) With | Without Outliers</td>\n",
       "      <td>14.354660</td>\n",
       "      <td>18.773125</td>\n",
       "      <td>-4.418465</td>\n",
       "      <td>0.4765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Linear) With | Without Outliers</td>\n",
       "      <td>46.971488</td>\n",
       "      <td>46.499993</td>\n",
       "      <td>0.471495</td>\n",
       "      <td>0.3683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(SVM) With | Without Outliers</td>\n",
       "      <td>22.169956</td>\n",
       "      <td>22.943743</td>\n",
       "      <td>-0.773787</td>\n",
       "      <td>0.5950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Comp Models  1st model (% error)  2nd model (% error)  \\\n",
       "0     (KNN) With | Without Outliers            21.870328            19.533164   \n",
       "0      (GP) With | Without Outliers            25.018578            22.502367   \n",
       "0      (RF) With | Without Outliers            14.354660            18.773125   \n",
       "0  (Linear) With | Without Outliers            46.971488            46.499993   \n",
       "0     (SVM) With | Without Outliers            22.169956            22.943743   \n",
       "\n",
       "   % error Diff  p value  \n",
       "0      2.337163   0.0184  \n",
       "0      2.516210   0.0516  \n",
       "0     -4.418465   0.4765  \n",
       "0      0.471495   0.3683  \n",
       "0     -0.773787   0.5950  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "664d6f14-2beb-45f4-ac8f-5eb515218c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp Models</th>\n",
       "      <th>1st model (% error)</th>\n",
       "      <th>2nd model (% error)</th>\n",
       "      <th>% error Diff</th>\n",
       "      <th>p value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(KNN) With | Without Outliers</td>\n",
       "      <td>21.870328</td>\n",
       "      <td>18.259551</td>\n",
       "      <td>3.610777</td>\n",
       "      <td>0.1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(GP) With | Without Outliers</td>\n",
       "      <td>25.018578</td>\n",
       "      <td>22.513272</td>\n",
       "      <td>2.505306</td>\n",
       "      <td>0.3795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(RF) With | Without Outliers</td>\n",
       "      <td>14.354660</td>\n",
       "      <td>13.463218</td>\n",
       "      <td>0.891442</td>\n",
       "      <td>0.0462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Linear) With | Without Outliers</td>\n",
       "      <td>46.971488</td>\n",
       "      <td>45.395348</td>\n",
       "      <td>1.576140</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(SVM) With | Without Outliers</td>\n",
       "      <td>22.169956</td>\n",
       "      <td>21.523516</td>\n",
       "      <td>0.646439</td>\n",
       "      <td>0.7133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Comp Models  1st model (% error)  2nd model (% error)  \\\n",
       "0     (KNN) With | Without Outliers            21.870328            18.259551   \n",
       "0      (GP) With | Without Outliers            25.018578            22.513272   \n",
       "0      (RF) With | Without Outliers            14.354660            13.463218   \n",
       "0  (Linear) With | Without Outliers            46.971488            45.395348   \n",
       "0     (SVM) With | Without Outliers            22.169956            21.523516   \n",
       "\n",
       "   % error Diff  p value  \n",
       "0      3.610777   0.1422  \n",
       "0      2.505306   0.3795  \n",
       "0      0.891442   0.0462  \n",
       "0      1.576140   0.0018  \n",
       "0      0.646439   0.7133  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c18c5df-83e5-4d38-acbd-258822939568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.67141017084106"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_LOD = 0.9117010154341669\n",
    "model_name = 'GP'\n",
    "with open('../models/Data_augmentation_outlier_remove_None/GP.pickle', 'rb') as f:\n",
    "    model = load(f)\n",
    "y_pred = model.predict(X_test[models_features_per[model_name]])\n",
    "\n",
    "per_error(y_test, y_pred, y_LOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dd8d126-8033-4154-ac04-f3b07e06a519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     16\n",
       "1      0\n",
       "2      8\n",
       "3     16\n",
       "4     16\n",
       "      ..\n",
       "41    16\n",
       "42    16\n",
       "43     8\n",
       "44     0\n",
       "45     8\n",
       "Name: file, Length: 145, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f43fcb-a87a-4886-9928-486f55b5c927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
