{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60bf6693-9201-488d-ac70-6cb6daa03ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.permutation_test import pair_permutation_test\n",
    "\n",
    "from glob import glob\n",
    "from pickle import load, dump\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.config import models_features_per\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "804577f3-a4e1-4697-ade0-a69d8d4a6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_create_training_data(train, test, blank_norm=False, remove_outlier=None):\n",
    "\n",
    "    # Remove outlier only from the training dataset\n",
    "    if remove_outlier=='all':\n",
    "        train = train[train['file'].apply(lambda x: False if (x.split('/')[-1].replace('.txt', '') in ouliners_to_remove) else True)]\n",
    "        test  = test[test['file'].apply(lambda x: False if (x.split('/')[-1].replace('.txt', '') in ouliners_to_remove) else True)]\n",
    "\n",
    "    elif remove_outlier=='train_only':\n",
    "        train = train[train['file'].apply(lambda x: False if (x.split('/')[-1].replace('.txt', '') in ouliners_to_remove) else True)]\n",
    "        \n",
    "    train = train.reset_index(drop=True)\n",
    "    test  = test.reset_index(drop=True)\n",
    "    \n",
    "    X_train = train.drop(columns=['file']).copy()\n",
    "    X_test  = test.drop(columns=['file']).copy()\n",
    "\n",
    "    columns       = X_train.columns\n",
    "    \n",
    "    y_train = train['file'].apply(lambda x: int(x.split('_')[-2].replace('cbz','')))\n",
    "    y_test  = test['file'].apply(lambda x: int(x.split('_')[-2].replace('cbz','')))\n",
    "\n",
    "    assert (X_train.index.values == y_train.index.values).all()\n",
    "\n",
    "    scaler  = StandardScaler()\n",
    "\n",
    "    if blank_norm: scaler.fit(X_train[y_train==0])\n",
    "    else: scaler.fit(X_train)\n",
    "\n",
    "    \n",
    "    X_train = pd.DataFrame(scaler.transform(X_train), columns=columns)\n",
    "    X_test  = pd.DataFrame(scaler.transform(X_test),  columns=columns)\n",
    "\n",
    "    X_train.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n",
    "                        'dS_dV_area':'univariate, area(dS/dV)', 'dS_dV_max_peak':'univariate, max(dS/dV)', 'dS_dV_min_peak':'univariate, min(dS/dV)',\\\n",
    "                    'dS_dV_peak_diff':'univariate, max(dS/dV) - min(dS/dV)', \\\n",
    "                    'peak V':'univariate, V_max(S)', 'dS_dV_max_V':'univariate, V_max(dS/dV)', 'dS_dV_min_V':'univariate, V_min(dS/dV)',\\\n",
    "        }, inplace = True)\n",
    "\n",
    "    X_test.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n",
    "                        'dS_dV_area':'univariate, area(dS/dV)', 'dS_dV_max_peak':'univariate, max(dS/dV)', 'dS_dV_min_peak':'univariate, min(dS/dV)',\\\n",
    "                    'dS_dV_peak_diff':'univariate, max(dS/dV) - min(dS/dV)', \\\n",
    "                    'peak V':'univariate, V_max(S)', 'dS_dV_max_V':'univariate, V_max(dS/dV)', 'dS_dV_min_V':'univariate, V_min(dS/dV)',\\\n",
    "        }, inplace = True)\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test), scaler\n",
    "\n",
    "def load_dataset_train_test_splitted(filename):\n",
    "    ML1 = pd.read_excel(f'/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_19_ML1/{filename}.xlsx')\n",
    "    ML2 = pd.read_excel(f'/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML1_ML2/2024_02_22_ML2/{filename}.xlsx')\n",
    "    ML4 = pd.read_excel(f'/Users/sangam/Desktop/Epilepsey/Code/vgramreg/dataset/ML4/{filename}.xlsx')\n",
    "\n",
    "    return ML1, ML2, ML4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f04f0fa-81b5-4b01-9369-0a8063cf530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML1_noisy_train, ML2_noisy_train, ML4_noisy_train = load_dataset_train_test_splitted('extracted_features_noisy_training_dataset')\n",
    "ML1_train, ML2_train, ML4_train = load_dataset_train_test_splitted('extracted_features_training_dataset')\n",
    "ML1_test, ML2_test, ML4_test = load_dataset_train_test_splitted('extracted_features_testing_dataset')\n",
    "\n",
    "# Test if training and testing has common dataset\n",
    "assert len(set(ML1_train['file'].values.tolist()) & set(ML1_test['file'].values.tolist()))==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "895abda7-f4c8-445d-8036-795027b82d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "data_propery   = 'noiseless' # noisy, both, and noiseless\n",
    "blank_norm     = False\n",
    "remove_outlier = ''\n",
    "\n",
    "if data_propery=='noisy':\n",
    "    (ML1_X_train, ML1_X_test, ML1_y_train, ML1_y_test), ML1_scalar = normalize_create_training_data(ML1_noisy_train, ML1_test, blank_norm, remove_outlier)\n",
    "    (ML2_X_train, ML2_X_test, ML2_y_train, ML2_y_test), ML2_scalar = normalize_create_training_data(ML2_noisy_train, ML2_test, blank_norm, remove_outlier)\n",
    "    (ML4_X_train, ML4_X_test, ML4_y_train, ML4_y_test), ML4_scalar = normalize_create_training_data(ML4_noisy_train, ML4_test, blank_norm, remove_outlier)\n",
    "    \n",
    "elif data_propery=='both':\n",
    "    ML1_train_combined = pd.concat([ML1_noisy_train, ML1_train])\n",
    "    ML2_train_combined = pd.concat([ML2_noisy_train, ML2_train])\n",
    "    ML4_train_combined = pd.concat([ML4_noisy_train, ML4_train])\n",
    "    \n",
    "    (ML1_X_train, ML1_X_test, ML1_y_train, ML1_y_test), ML1_scalar = normalize_create_training_data(ML1_train_combined, ML1_test, blank_norm, remove_outlier)\n",
    "    (ML2_X_train, ML2_X_test, ML2_y_train, ML2_y_test), ML2_scalar = normalize_create_training_data(ML2_train_combined, ML2_test, blank_norm, remove_outlier)\n",
    "    (ML4_X_train, ML4_X_test, ML4_y_train, ML4_y_test), ML4_scalar = normalize_create_training_data(ML4_train_combined, ML4_test, blank_norm, remove_outlier)\n",
    "    \n",
    "else:\n",
    "    (ML1_X_train, ML1_X_test, ML1_y_train, ML1_y_test), ML1_scalar = normalize_create_training_data(ML1_train, ML1_test, blank_norm, remove_outlier)\n",
    "    (ML2_X_train, ML2_X_test, ML2_y_train, ML2_y_test), ML2_scalar = normalize_create_training_data(ML2_train, ML2_test, blank_norm, remove_outlier)\n",
    "    (ML4_X_train, ML4_X_test, ML4_y_train, ML4_y_test), ML4_scalar = normalize_create_training_data(ML4_train, ML4_test, blank_norm, remove_outlier)\n",
    "\n",
    "\n",
    "X_train = pd.concat([ML1_X_train, ML2_X_train, ML4_X_train], axis=0)\n",
    "y_train = pd.concat([ML1_y_train, ML2_y_train, ML4_y_train], axis=0)\n",
    "\n",
    "indx_shuffle = np.random.permutation(range(len(X_train)))\n",
    "X_train      = X_train.iloc[indx_shuffle]\n",
    "y_train      = y_train.iloc[indx_shuffle]\n",
    "\n",
    "X_test  = pd.concat([ML1_X_test,  ML2_X_test,  ML4_X_test], axis=0)\n",
    "y_test  = pd.concat([ML1_y_test,  ML2_y_test,  ML4_y_test], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b933646c-0eca-4a98-8615-a3ba0ecb14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root_path = os.path.realpath('../models')\n",
    "\n",
    "model_1_path  = os.path.join(model_root_path, 'Data_noiseless_outlier_remove_None')\n",
    "model_2_path  = os.path.join(model_root_path, 'Data_augmentation_outlier_remove_None')\n",
    "\n",
    "models_1      =  glob(f'{model_1_path}/*.pickle')\n",
    "models_2      =  glob(f'{model_2_path}/*.pickle')\n",
    "\n",
    "common_models = set([os.path.basename(i) for i in models_1]) & set([os.path.basename(i) for i in models_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38e46fd6-4f35-474d-89d2-bbb668089dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                       | 0/5 [00:00<?, ?it/s]/var/folders/6p/0ctyq1md3qqbfn509nf4xfgr0000gp/T/ipykernel_50718/570906581.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  permutation_test_results = pd.concat([permutation_test_results, temp], axis=0)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:29<00:00,  5.94s/it]\n"
     ]
    }
   ],
   "source": [
    "permutation_test_results = pd.DataFrame(columns=['Comp Models', 'R2 Diff', '% error Diff', 'p value' ])\n",
    "y_LOD = 0.9117010154341669\n",
    "\n",
    "for model_file_name in tqdm(common_models):\n",
    "    model_name = model_file_name.replace('.pickle', '')\n",
    "    with open(os.path.join(model_1_path, model_file_name), 'rb') as f:\n",
    "        model_1 = load(f)\n",
    "\n",
    "    with open(os.path.join(model_2_path, model_file_name), 'rb') as f:\n",
    "        model_2 = load(f)\n",
    "\n",
    "    model1_pred = model_1.predict(X_test[models_features_per[model_name]])\n",
    "    model2_pred = model_2.predict(X_test[models_features_per[model_name]])\n",
    "\n",
    "    observed_r2_score, observed_statistic, p_value, _, _ = pair_permutation_test(model1_pred, model2_pred, y_test, y_LOD)\n",
    "    temp = pd.DataFrame({'Comp Models':['() Without Aug | With Aug'], 'R2 Diff':[observed_r2_score], '% error Diff':[observed_statistic], 'p value':[p_value]})\n",
    "\n",
    "    permutation_test_results = pd.concat([permutation_test_results, temp], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68d140d9-260d-4a3a-b942-136ce69e474e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp Models</th>\n",
       "      <th>R2 Diff</th>\n",
       "      <th>% error Diff</th>\n",
       "      <th>p value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Without Aug | With Aug</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>1.958394</td>\n",
       "      <td>0.3406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Without Aug | With Aug</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.070601</td>\n",
       "      <td>0.9749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Without Aug | With Aug</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>2.136466</td>\n",
       "      <td>0.0076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Without Aug | With Aug</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>10.684698</td>\n",
       "      <td>0.0241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Without Aug | With Aug</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>13.347617</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Comp Models   R2 Diff  % error Diff  p value\n",
       "0  Without Aug | With Aug  0.002564      1.958394   0.3406\n",
       "0  Without Aug | With Aug  0.008627      0.070601   0.9749\n",
       "0  Without Aug | With Aug  0.000262      2.136466   0.0076\n",
       "0  Without Aug | With Aug  0.019530     10.684698   0.0241\n",
       "0  Without Aug | With Aug  0.026555     13.347617   0.0010"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "664d6f14-2beb-45f4-ac8f-5eb515218c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpair_permutation_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel1_pred\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel2_pred\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mground_truth\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_LOD\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Calculates Statistical Significance level p-value for the given pair\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Desktop/Epilepsey/Code/vgramreg/src/permutation_test.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair_permutation_test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c18c5df-83e5-4d38-acbd-258822939568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
