{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5663283-9384-43f6-921e-c832d1b9e5c7",
   "metadata": {},
   "source": [
    "## Following experiments are being performed in this notebook\n",
    " 1) Use Features extracted from ML12\n",
    " 2) Training ML12\n",
    " 3) Check the generability when ML12 is normalized with only the blanks and ML4 is normalized only with the blanks\n",
    " 4) Testing 5 fold <br>\n",
    "        -> Calculate the variance and mean only from 4 folds (only from the blanks) and test on 1 fold <br>\n",
    "\t\t-> Repeat for every fold.\n",
    "\n",
    "## Blank feature comparison between ML12 and ML4\n",
    "```\n",
    "                                        Mean ML12         ML4\n",
    " univariate, area(S)                     0.625470         0.338291\n",
    " peak curvature                         35.631810         36.161643\n",
    " univariate, V_max(S)                    1.012192         1.007822\n",
    " vcenter                                 1.015360         1.016870\n",
    " univariate, max(S)                      0.008779         0.006264\n",
    " univariate, mean(S)                     0.000892         0.000487\n",
    " univariate, std(S)                      0.002334         0.002030\n",
    " univariate, max(dS/dV)                  0.296886         0.307639\n",
    " univariate, min(dS/dV)                 -0.284828         -0.265513\n",
    " univariate, max(dS/dV) - min(dS/dV)     0.581714         0.573135       \n",
    " univariate, V_max(dS/dV)                0.981520         0.998957\n",
    " univariate, V_min(dS/dV)                1.045040         1.025391\n",
    " univariate, area(dS/dV)                 0.017548         0.012530\n",
    "```\n",
    "\n",
    "The difference between the two different dataset for blank is close\n",
    "\n",
    "## label 8 feature comparison between ML12 and ML4\n",
    "```\n",
    "                                        Mean ML12        Mean ML4\n",
    " univariate, area(S)                     3.544772        7.607660\n",
    " peak curvature                         80.466083        192.092580\n",
    " univariate, V_max(S)                    1.056402        1.048924\n",
    " vcenter                                 1.056426        1.050648\n",
    " univariate, max(S)                      0.054969        0.122838\n",
    " univariate, mean(S)                     0.005053        0.010868\n",
    " univariate, std(S)                      0.013428        0.029184\n",
    " univariate, max(dS/dV)                  1.221215        2.677500\n",
    " univariate, min(dS/dV)                 -1.391168        -3.465284\n",
    " univariate, max(dS/dV) - min(dS/dV)     2.612391        6.142800\n",
    " univariate, V_max(dS/dV)                1.025362        1.021280\n",
    " univariate, V_min(dS/dV)                1.080255        1.075200\n",
    " univariate, area(dS/dV)                 0.109943        0.245688\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3687771c-df07-453c-8dbb-492e5a7cb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from typing import Tuple\n",
    "from pycombat import Combat\n",
    "\n",
    "from src.load_models import select_model\n",
    "from src.load_dataset import load_dataset, select_normalizer\n",
    "from src.config import models_features_r2, models_features_per, model_name_conversion\n",
    "from src.graph_visualization import visualize_highest_score_feature_selection, feature_selection_tabularize, visualization_testing_dataset\n",
    "\n",
    "from src.utils import find_adj_score, calculate_y_LOD, per_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01038b8-3206-4225-8f6c-e596b1eab9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x13fb759a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangam/Desktop/Epilepsey/Code/vgramreg/src/load_dataset.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n",
      "/Users/sangam/Desktop/Epilepsey/Code/vgramreg/src/load_dataset.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n",
      "/Users/sangam/Desktop/Epilepsey/Code/vgramreg/src/load_dataset.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.rename(columns={\"PH\": 'univariate, max(S)', 'signal_std':'univariate, std(S)', 'signal_mean':'univariate, mean(S)', 'peak area':'univariate, area(S)', \\\n"
     ]
    }
   ],
   "source": [
    "# Load Training Dataset\n",
    "normalize_blanks   = False\n",
    "normalization      = True\n",
    "use_training_scale = False\n",
    "standardize_type   = 'mean_std'\n",
    "\n",
    "%matplotlib\n",
    "ML1_X, ML1_y  = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/ML1_ML2/2024_02_19_ML1', normalization=normalization, standardize_type=standardize_type, split=False)\n",
    "ML2_X, ML2_y  = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/ML1_ML2/2024_02_22_ML2', normalization=normalization, standardize_type=standardize_type, split=False)\n",
    "ML4_X, ML4_y      = load_dataset('/Users/sangam/Desktop/Epilepsey/Code/vgramreg/ML4', normalization=normalization, standardize_type=standardize_type, split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d304987-cf1f-416e-a6d1-82f873de659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "# X, y     = pd.concat([ML1_X, ML2_X], axis=0), pd.concat([ML1_y, ML2_y], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31c3245-02e7-4750-aa44-53068ea6dbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_LOD 0.9117010154341676\n"
     ]
    }
   ],
   "source": [
    "models = ['Linear', 'KNN', 'SVM', 'RF', 'GP', 'Ridge', 'Lasso', 'univariate, std(S)', 'univariate, max(dS/dV)', 'univariate, area(dS/dV)', 'univariate, area(S)', 'univariate, max(S)']\n",
    "metric = 'per_error'\n",
    "nor_with_blank = False\n",
    "\n",
    "scorer = make_scorer((r2_score if metric=='r2' else per_error), greater_is_better=(True if metric=='r2' else False))\n",
    "\n",
    "score_dict_r2 = {'Models': [],\n",
    "              'Scores': []}\n",
    "\n",
    "score_dict_per = {'Models': [],\n",
    "              'Scores': []}\n",
    "\n",
    "\n",
    "training_dataset = 'ML12'\n",
    "testing_dataset  = 'ML4'\n",
    "\n",
    "# Calcualte y_LOD\n",
    "y_LOD = 0.9117010154341676\n",
    "print(\"y_LOD\", y_LOD)\n",
    "\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b04b4c1-6633-45f6-8121-d994f6748d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.030e+02, tolerance: 1.075e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.031e+02, tolerance: 1.075e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.061e+02, tolerance: 1.075e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.071e+02, tolerance: 1.075e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/sangam/miniconda3/envs/vgramreg/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.985e+02, tolerance: 1.075e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Models': ['Linear',\n",
       "   'KNN',\n",
       "   'SVM',\n",
       "   'RF',\n",
       "   'GP',\n",
       "   'Ridge',\n",
       "   'Lasso',\n",
       "   'univariate, std(S)',\n",
       "   'univariate, max(dS/dV)',\n",
       "   'univariate, area(dS/dV)',\n",
       "   'univariate, area(S)',\n",
       "   'univariate, max(S)'],\n",
       "  'Scores': [(0.8295665632298912, 0.8217485156716293),\n",
       "   (0.8937724631352659, 0.8899096436129119),\n",
       "   (0.8988743374052509, 0.8922586398523233),\n",
       "   (0.8857362965074588, 0.8836958732308062),\n",
       "   (0.8920369517348361, 0.8910815265289497),\n",
       "   (0.8362742456375137, 0.8255632149782857),\n",
       "   (0.8301777007446831, 0.822387687017375),\n",
       "   (0.8754192692874051, 0.8743167849448158),\n",
       "   (0.8832851302875492, 0.8822522553343417),\n",
       "   (0.877876768618915, 0.8767960320580204),\n",
       "   (0.8732562811476315, 0.8721346553170797),\n",
       "   (0.8778745954565963, 0.8767938396641768)]},\n",
       " {'Models': ['Linear',\n",
       "   'KNN',\n",
       "   'SVM',\n",
       "   'RF',\n",
       "   'GP',\n",
       "   'Ridge',\n",
       "   'Lasso',\n",
       "   'univariate, std(S)',\n",
       "   'univariate, max(dS/dV)',\n",
       "   'univariate, area(dS/dV)',\n",
       "   'univariate, area(S)',\n",
       "   'univariate, max(S)'],\n",
       "  'Scores': [42.80917808537001,\n",
       "   28.311181393307237,\n",
       "   18.575602700508465,\n",
       "   28.810944585275422,\n",
       "   33.03273353877341,\n",
       "   44.57062350333272,\n",
       "   43.24246208073874,\n",
       "   28.582356734458397,\n",
       "   32.47875999002669,\n",
       "   29.414138876193817,\n",
       "   31.338191361070113,\n",
       "   29.417515249176763]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name in models:\n",
    "\n",
    "    # Test for R2 score\n",
    "    model    = select_model(model_name)\n",
    "\n",
    "    model_r2  = clone(model)\n",
    "    model_per = clone(model)\n",
    "  \n",
    "    y_pred_r2  = []\n",
    "    y_pred_per = []\n",
    "    y_gt       = []\n",
    "    \n",
    "    for train_ind, test_ind in kf.split(ML4_X):\n",
    "        # Features\n",
    "        X_train_temp = ML4_X.iloc[train_ind].copy()\n",
    "        X_test_temp  = ML4_X.iloc[test_ind].copy()\n",
    "\n",
    "        # labels\n",
    "        y_train_temp = ML4_y.to_numpy()[train_ind].copy()\n",
    "        y_test_temp  = ML4_y.to_numpy()[test_ind].copy()\n",
    "\n",
    "\n",
    "        # Concat ML12 with ML4 four folds\n",
    "        features      = pd.concat([ML1_X, ML2_X, X_train_temp])\n",
    "        batch_labels  = np.repeat(['ML1', 'ML2', 'ML4'], repeats= [len(ML1_X), len(ML2_X), len(y_train_temp)])\n",
    "\n",
    "        combat        = Combat()\n",
    "        combat_scaler = combat.fit(features.values, batch_labels)\n",
    "\n",
    "        training      = combat_scaler.transform(pd.concat([ML1_X, ML2_X, X_test_temp]).values, np.repeat(['ML1', 'ML2', 'ML4'], repeats= [len(ML1_X), len(ML2_X), len(y_test_temp)]))\n",
    "        training      = pd.DataFrame(training, columns=ML1_X.columns)\n",
    "\n",
    "        X_training   = training.iloc[0:len(ML1_X)+len(ML2_X)]\n",
    "        X_test_temp  = training.iloc[len(ML1_X)+len(ML2_X):]\n",
    "\n",
    "        y_training   = pd.concat([ML1_y, ML2_y], axis=0)\n",
    "\n",
    "        assert len(X_test_temp) == len(y_test_temp)\n",
    "        \n",
    "        model_r2.fit(X_training[models_features_r2[model_name]],   y_training)                 # Fit model with R2 features on ML1_2 dataset\n",
    "        model_per.fit(X_training[models_features_per[model_name]], y_training)                 # Fit percent error with R2 features on ML1_2 dataset\n",
    "\n",
    "        y_pred_r2  += model_r2.predict(X_test_temp[models_features_r2[model_name]]).tolist()      # Inference model with R2 features on ML4 dataset\n",
    "        y_pred_per += model_per.predict(X_test_temp[models_features_per[model_name]]).tolist()    # Inference percent error features on ML4 dataset\n",
    "\n",
    "        y_gt       += y_test_temp.tolist()\n",
    "  \n",
    "    r2Score      = r2_score(y_gt, y_pred_r2)\n",
    "    adj_r2_Score = find_adj_score(len(y_gt), len(models_features_r2[model_name]), r2Score)\n",
    "\n",
    "    score_dict_r2['Models'].append(model_name)\n",
    "    score_dict_per['Models'].append(model_name)\n",
    "    \n",
    "    score_dict_r2['Scores'].append((r2Score, adj_r2_Score))\n",
    "    score_dict_per['Scores'].append(per_error(pd.Series(y_gt), y_pred_per, y_LOD=y_LOD))\n",
    "\n",
    "score_dict_r2, score_dict_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8edf3f0b-8de5-4e1b-b26f-c9bab24527c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir      = 'Generability_output_diff_mean_std'\n",
    "r2_savefile  = f'{savedir}/r2_score_D_{training_dataset}_T_{testing_dataset}_sTrain_{use_training_scale}_nBlank_{normalize_blanks}_nType_{standardize_type}_ComBat.png'\n",
    "per_savefile = f'{savedir}/per_error_score_D_{training_dataset}_T_{testing_dataset}_sTrain_{use_training_scale}_nBlank_{normalize_blanks}_nType_{standardize_type}_ComBat.png'\n",
    "\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "visualization_testing_dataset(score_dict_r2,  r2_savefile,  model_name_conversion, only_one_multivariate=False, adj_score=True, legends=True)\n",
    "visualization_testing_dataset(score_dict_per, per_savefile, model_name_conversion, only_one_multivariate=False, r2_score=False, adj_score=False, legends=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb67a6d7-11d3-456c-8d67-ad468cf79c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715293f7-175f-4a16-9719-a8701977aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_temp==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348474fc-fbdb-49ba-8903-d268ea3321fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
